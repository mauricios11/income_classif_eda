# ğŸ’¸ PredicciÃ³n de Ingresos Anuales a partir de Datos demogrÃ¡ficos ğŸ’¸

## ğŸ“ DescripciÃ³n
Este proyecto se centra en la predicciÃ³n de ingresos anuales usando un dataset del *Census Bureau* de los EEUU. Contiene informaciÃ³n demogrÃ¡fica y econÃ³mica de mÃ¡s de $45,000$ sujetos. El objetivo principal es predecir si una persona tiene un ingreso mayor a $USD $50$ k al aÃ±o basado en sus caracterÃ­sticas personales y laborales.
* **objetivos**: A parte de entrenar un `RandomForest` como modelo final para realizar predicciones, el principal objetivo del proyecto es evitar tomar decisiones arbitrarias. A lo largo del anÃ¡lisis, nos enfocamos en justificar cada elecciÃ³n mediante evaluaciones estadÃ­sticas
* *(bitÃ¡cora al final del README)*

### DescripciÃ³n de variables
* **(1) age**: edad del sujeto
* **(2) workclass**: Tipo de trabajo / sector al que pertenece el individuo *(gobierno, privado, sin empleo, etc.)*.
* **(3) fnlwgt**: Peso final del individup en la encuesta (descripciÃ³n de esta variable mÃ¡s abajo) 
* **(4) education_num**: Nivel educativo del individuo *(formato numÃ©rico)* correspondiente a los aÃ±os de educaciÃ³n completados
* **(5) marital_status**: Estado civil del individuo *(soltero, casado, etc.)*
* **(6) occupation**: A quÃ© se dedica *(ejecutivo, obrero, empleado de gobierno, etc)*.
* **(7) relationship**: Rol **familiar** que el individuo asume dentro del hogar *(jefe de hogar, esposo/a)*.
* **(8) ethnicity**: Etnia del individuo *(Blanco, negro, asiÃ¡tico)*.
* **(9) genre**: gÃ©nero del individuo
* **(10) capital_gain**: Ganancias de vapital adicionales, fuera del salario o ingresos laborales
* **(11) capital_loss**: PÃ©rdidas de capital adicionales
* **(12) hours_per_week**: Horas trabajadas por semana
* **(14) native_country**: PaÃ­s de origen del indiviuo
* **(15) income**: Variable objetivo.
    * no $=$ salario USD$<= 50k$ anuales **(individuo gana 50k anuales o menos)**
    * yes  $=$ salario USD$> 50k$ anuales **(individuo gana mÃ¡s de 50k anuales)**

## ğŸ› ï¸ Deployment del modelo
El modelo de clasificaciÃ³n entrenado durante este proyecto ha sido desplegado en **streamlit.io**.
* Puedes ingresar a: "[Income Prediction APP](https://mauricios11-random-forest-deployment.streamlit.app)" para probarlo. *(estÃ¡ en inglÃ©s porque ando muy bilingÃ¼e ğŸ¤­ :D)*
* El repositorio del deployment estÃ¡ en el siguiente enlace: "[Random Forest Deployment](https://github.com/mauricios11/random_forest_deployment)"

### ğŸ“š AclaraciÃ³n de entornos implementados
Trabajamos con dos entornos distintos debido a problemas de compatibilidad entre versiones:.
* **Entorno 1 (EDA)**: Downgrade a`scikit-learn==1.5.2` para evitar advertencias al usar `xgboost`.
* **Entorno 2 (Imbalanced)**: Downgrade a `scikit-learn==1.2.2` para usar `imblearn` durante el balanceo de datos.

### â„¹ï¸ instalaciÃ³n del proyecto:
âœ‚ï¸ En un nuevo directorio para el proyecto, ejecuta el siguiente comando:
```
git clone https://github.com/mauricios11/income_classif_eda.git
```
âœ‚ï¸ **entorno 1: (eda)**:

anaconda
```
conda env create -f eda_environment.yml
conda activate eda
```
pip
```
python -m venv eda
source eda/bin/activate  # Windows: eda\Scripts\activate
pip install -r eda_requirements.txt
```
âœ‚ï¸ **entorno 2: (imbalanced)**

anaconda *(instalar imblearn con pip)*
```
conda env create -f imbalanced_environment.yml
conda activate imbalanced
pip install imblearn
```
pip
```
python -m venv imbalanced
source imbalanced/bin/activate  # Windows: imbalanced\Scripts\activate
pip install -r imbalanced_requirements.txt
```
Si tienen algÃºn problema con la instalaciÃ³n de librerÃ­as $\rightarrow$ just hit me up :D *(recomiendo usar anaconda)*

### ğŸ“ Estructura del proyecto
```
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ clean
â”‚Â Â  â””â”€â”€ raw
â”‚Â Â      â”œâ”€â”€ adult.csv
â”‚Â Â      â”œâ”€â”€ adult_complete.csv
â”‚Â Â      â”œâ”€â”€ adult_test.test
â”‚Â Â      â””â”€â”€ adult_validation.csv
â”œâ”€â”€ description.txt
â”œâ”€â”€ modules                           # MÃ³dulos auxiliares (listas, diccionarios, mÃ©todos)
â”‚Â Â  â”œâ”€â”€ list_and_dicts.py             # listas y diccionarios
â”‚Â Â  â”œâ”€â”€ module_discarted_methods.py   # registro de procesos descartados durante el anÃ¡lisis (bajo desempeÃ±o)
â”‚Â Â  â”œâ”€â”€ module_imbalanced.py          # mÃ©todos implementados durande el procedo de balanceo
â”‚Â Â  â”œâ”€â”€ module_imputation.py          # para el proceso de imputaciÃ³n
â”‚Â Â  â”œâ”€â”€ module_modeling.py            # entrenamiento de varios modelos
â”‚Â Â  â””â”€â”€ import_modules.py             # Archivo para manejar todas las importaciones al nb
â”œâ”€â”€ models                            # Modelos entrenados (leer txt)
â”œâ”€â”€ notebooks
â”‚Â Â  â”œâ”€â”€ 00_initial_EDA.ipynb          # EDA inicial
â”‚Â Â  â”œâ”€â”€ 01_EDA_missing.ipynb          # EDA e imputaciÃ³n para valores nulos
â”‚Â Â  â”œâ”€â”€ 02_imbalanced.ipynb           # balanceo de target con dos diferentes mÃ©todos
â”‚Â Â  â”œâ”€â”€ 03_model_training.ipynb       # entrenamiento del modelo final (diferentes mÃ©todos)
â”‚Â Â  â”œâ”€â”€ 03_training_input.txt         # muestra de uno de los inputs del entrenamiento
â”‚Â Â  â””â”€â”€ import_modules.py             # Archivo para manejar todas las importaciones al nb
â”œâ”€â”€ scripts
â”‚Â Â  â”œâ”€â”€ load_data.py                  # Funciones para cargar los datos
â”‚Â Â  â”œâ”€â”€ utils.py                      # Funciones generales
â”‚Â Â  â”œâ”€â”€ utils_categorical_plots.py    # GrÃ¡ficos para variables categÃ³ricas
â”‚Â Â  â”œâ”€â”€ utils_classif_models_plots.py # GrÃ¡ficos relacionados con modelos de clasificaciÃ³n
â”‚Â Â  â”œâ”€â”€ utils_initial_exploration.py  # ExploraciÃ³n inicial
â”‚Â Â  â”œâ”€â”€ utils_missing_extension.py    # Extensiones para manejo de nulos en pandas
â”‚Â Â  â”œâ”€â”€ utils_missing_extension_plots.py # GrÃ¡ficos para manejo de nulos
â”‚Â Â  â””â”€â”€ utils_probability_funcs.py    # Funciones para cÃ¡lculos probabilÃ­sticos
```

### ğŸ“° BitÃ¡cora de procesos
#### ğŸ•µï¸â€â™€ï¸ ExploraciÃ³n de Datos (EDA)
Iniciamos estudiando el comportamiento general de las variables. No se encontraron relaciones lineales significativas, lo que llevÃ³ a investigar posibles relaciones no lineales.

* **Manejo de valores nulos**: Se detectaron nulos implÃ­citos como 'unknown'. Columnas con prefijos como "_other" no fueron modificadas, ya que representaban casos reales pero poco comunes.

* **ImputaciÃ³n de valores**: Se probaron dos mÃ©todos de imputaciÃ³n: por moda y un `DecisionTreeClassifier`, siendo este Ãºltimo el de mejor desempeÃ±o.

* **Balanceo de datos**: Se utilizaron dos tÃ©cnicas `SMOTE` *(oversampling)* y una combinaciÃ³n de oversampling + undersampling con un RandomForestClassifier. SMOTE resultÃ³ ligeramente superior. 
    * Ajustamos la cantidad de muestras balanceadas para maximizar el f1-score.

* ğŸ” **SelecciÃ³n de variables**: Identificamos las columnas mÃ¡s importantes usando:
    * `Feature Importances` + `RandomForest`.
    * `Mutual Information` *(anÃ¡lisis de dependencia)*.
    * En adiciÃ³n, evaluamos el uso de `PCA` para reducir dimensionalidad, pero los resultados fueron inferiores, ya que la mayorÃ­a de las variables eran categÃ³ricas.

### âŒ Dificultades con fnlwgt
Durante el EDA, la columna `fnlwgt` destacÃ³ como una variable significativa para la predicciÃ³n. Sin embargo, detectamos que en un contexto prÃ¡ctico, a la hora de desplgegar el modelo el usuario no tendrÃ­a acceso a este valor.

* **Estrategia fallida**: Aceptamos el desafÃ­o de predecir `fnlwgt` usando modelos como: *Random Forest, XGBoost, LightGBM, SVR* y un *ensemble stacking*.
    * A pesar de optimizar hiperparÃ¡metros y agregar variables derivadas (como `capital_net`), los resultados fueron insatisfactorios
    * MÃ©tricas tales como RÂ², MAE y RMSE reflejaron que el modelo era incapaz de generalizar.

* **ReflexiÃ³n**: Ignorar seÃ±ales iniciales del EDA *(y estar de necios)* nos llevÃ³ a invertir tiempo en un reto poco prÃ¡ctico.
    * A veces, es mejor replantear estrategias en lugar de insistir en soluciones poco factibles.

* **Nueva estrategia**: Se descartÃ³ `fnlwgt` y se probÃ³ con diferentes configuraciones de variables:
    * *df_no_capital*: Sin columnas adicionales (7 variables)
    * *df_capital_gain*: Incluyendo capital_gain (8 variables).
    * *df_capital_net*: Con la derivada capital_net (8 variables)

### ğŸ¤– Entrenamiento del Modelo

* **Primera iteraciÃ³n**: Entrenamos un `RandomForestClassifier` +  `GridSearchCV`, pero tuvo un desempeÃ±o inferior.
* **Modelo final**: Implementamos un `StackingClassifier` combinando $\rightarrow$ 
    * `RandomForestClassifier` +  `XGBoostClassifier` (cada uno optimizado con gridsearch)
    * Administramos el pipeline completo para garantizar escalabilidad y reproducibilidad

### ğŸŒ Despliegue del Modelo

* **ExportaciÃ³n del modelo**: Tras seleccionar el mejor modelo, lo exportamos para su despliegue en Streamlit.
* **DesafÃ­os durante el despliegue**: El modelo excedÃ­a el lÃ­mite de GitHub. Para arreglarlo usamos `Git LFS` para manejar archivos pesados.
    * otra alternativa hubiera sido comprimir el modelo.

* **Resultado final**: El modelo estÃ¡ desplegado en Streamlit. Los usuarios pueden predecir ingresos anuales en funciÃ³n de los parÃ¡metros introducidos